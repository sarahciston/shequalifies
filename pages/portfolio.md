---
title: portfolio
<!-- permalink: portfolio -->
nav_order: 90
last_modified_date: 2020-09-06 18:46
<!-- has_children: true -->
---

# portfolio

Thank you for viewing! Please engage these projects in the order they appear below:

## she qualifies site

<iframe src="https://player.vimeo.com/video/455126495" width="800" height="450" frameborder="0" allow="autoplay; fullscreen" allowfullscreen></iframe>
<!-- 1100, 619 -->

Explore this extended qualifying exam site--specifically focusing on its form and format, programming as performance, code and content in relation. See the [code here](https://glitch.com/edit/#!/shequalifies). 

<!-- _* note to self: For the qualifying exam portfolio maybe I will make a page charting all the collected data, too bad the dialogue wont likely be auto captioned from these videos, won't capture all the icky feeling from producing these documents, the cumulative sleep, the total words divided by, weight lost/gained, etc._ -->

<!-- ~~[glossary], and organizing metaphors: [labyrinth], [jellyfish], [moiré]~~  -->

<!-- ![](https://cdn.glitch.com/eaa18b38-3765-4c0b-8304-2af139b6b542%2Fkikiwatch3.png?v=1599506940479){: width="400px" } -->
<!-- ![](https://cdn.glitch.com/eaa18b38-3765-4c0b-8304-2af139b6b542%2Fkikiwatch2.png?v=1599506940844){: width="400px" } -->
![](https://cdn.glitch.com/eaa18b38-3765-4c0b-8304-2af139b6b542%2Fkikiwatchingstream.jpg?v=1599504620904){: width="400px" }

[glossary]: /posts/glossary 
[labyrinth]: /posts/field1-labyrinth
[jellyfish]: /posts/field2-jellyfish
[moiré]: /posts/field3-moire

---

## inner voice over
<!-- [read] about the project, hear from the [self-compassion database] & add your voice, see the [code] -->

![](https://cdn.glitch.com/eaa18b38-3765-4c0b-8304-2af139b6b542%2FMtLFAI1.JPG?v=1599262508317)

<!-- # inner(voice)over -->

- Make sure to listen to the [self-compassion database], and feel free to add your voice
- see the [code]

Could AI rewrite one's inner critic? _inner(voice)over_ combines AI speech-to-text analysis and text-to-speech synthesis to question the origins of inner voices and to shift what influences an individual's outlook. Users speak a kind phrase into its acoustic dishes, and _inner(voice)over_ uses Mozilla DeepSpeech to anonymize their words and add them to its self-compassion database. Then users can hear what others have shared, restated in a synthesized AI voice.

By collaboratively rewriting a communal inner voice using AI---and by attending to imperfections of technological and human communications alike---this experiment explores the possibility of influencing each other through language altered across digital distances.

Featured in _IMAPPENING_ exhibition, Apr 2019, University of Southern California, and as part of a solo exhibition, _Modify the Loss_, Nov-Dec 2019, [Feminist.AI](https://www.feminist.ai/), Los Angeles.

### [latest work: web app]
<!-- (http://innervoiceover.com){:target="_blank"}  -->

I'm interested in how the physical, communal experience can translate or expand into fully digital, distributed spaces. I've spent this summer rebuilding the database on a new server, and I will need to find a new AI voice synthesis solution soon. In the meantime I am considering an "organic"-intelligent solution, recording the text-to-speech as homemade ASMR recordings, as a form of "mechanical turking" or performing database care. A web app has also been in development (suffering some setbacks due to bought-out startups and open-source APIs going private). 

![](https://cdn.glitch.com/eaa18b38-3765-4c0b-8304-2af139b6b542%2FMtLFAI2.JPG?v=1599262508868)
![](https://cdn.glitch.com/eaa18b38-3765-4c0b-8304-2af139b6b542%2FMtLFAI4.JPG?v=1599262507180)
<!-- ![](https://cdn.glitch.com/eaa18b38-3765-4c0b-8304-2af139b6b542%2FMtLFAI5.jpg?v=1599262504947){: width="400px" } -->
<!-- ![](https://cdn.glitch.com/eaa18b38-3765-4c0b-8304-2af139b6b542%2FMtLFAI3.jpg?v=1599262506648){: width="400px" } -->
<!-- ![](https://cdn.glitch.com/eaa18b38-3765-4c0b-8304-2af139b6b542%2Finnervoiceover-imap2019-2.jpg?v=1599262694127) -->
<!-- ![](https://cdn.glitch.com/eaa18b38-3765-4c0b-8304-2af139b6b542%2Finnervoiceover-imap2019-1.jpg?v=1599262687164) -->
 
<!-- [innervoiceover.com]: http://innervoiceover.com{:target="_blank"}  -->
<!-- [web app version]: http://innervoiceover.com{:target="_blank"}  -->
<!-- [self-compassion database]: http://innervoiceover.com{:target="_blank"}  -->
<!-- [code]: https://glitch.com/edit/#!/innervoiceover{:target="_blank"}  -->

---

## modify the loss
<!-- [exhibition report] : additional background on the project in process -->

<iframe width="825" height="464" src="https://www.youtube.com/embed/OI4fgy3zCOE" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<!-- 560, 315 -->
<!-- # modifytheloss -->

A participatory interaction and contemplative investigation, this reworking of the ancient archetype of the labyrinth is both a poetic text and a community gesture developing over the exhibition. It will build from analog data gathering into a networked, touch-sensitive multimedia installation considering intersections of queerness, code, and trauma--starting from the loss function, which in machine learning aims to minimize error, so that the machine behaves as intended.

What does it mean to process code, through both bodies and machines? _MODIFY THE LOSS_ explores the absurd and tender aspects of our entangled encounters with technology and each other. What are embodied modes of processing—both code and trauma? How do we write, re-write, and collaborate on the codes and stories we carry with us? It uses the gallery as an active, collaborative research lab and performance space, responding with audiences in recursive feedback loops.

Featured at _Modify the Loss_, a solo exhibition at [Feminist.AI](https://www.feminist.ai/), Nov-Dec 2019, Los Angeles.

![](https://cdn.glitch.com/eaa18b38-3765-4c0b-8304-2af139b6b542%2FMtL1.jpg?v=1599262510979)
![](https://cdn.glitch.com/eaa18b38-3765-4c0b-8304-2af139b6b542%2FMtL2.jpg?v=1599262509319){: width="400px" }
![](https://cdn.glitch.com/eaa18b38-3765-4c0b-8304-2af139b6b542%2FMtL3.png?v=1599262508224){: width="422px" }

![](https://cdn.glitch.com/eaa18b38-3765-4c0b-8304-2af139b6b542%2FlabyrinthARtest.png?v=1599262509007){: width="400px" .image-left }

### latest work: digital experiments

Over the summer I did some early experiments with how to bring my physical installation to distributed-but-shared digital spaces, given the extreme constraints for physical co-presence and community participatory projects. Here's one test using Spark AR Studio.

I'm also continuing to explore applying im2txt and other image- and text-focused algorithms to the project. 

<br><br><br><br><br><br><br><br><br><br><br>

<!-- include data from AI processes, excerpts from essay? -->

<!-- [modifytheloss]: https://sarahciston.com/MtL.html{:target="_blank"}  -->

### process-oriented arts-based research

[exhibition report] : additional details on gallery installation as research 

<iframe src="https://player.vimeo.com/video/380137928?title=0&byline=0&portrait=0" width="800" height="600" frameborder="0" allow="autoplay; fullscreen" allowfullscreen></iframe>

[exhibition report]: https://medium.com/@sarahciston/modify-the-loss-the-art-of-losing-29dfbf3d9750{:target="_blank"} 

---

### [full portfolio at sarahciston.com](https://sarahciston.com){:target="_blank"}

<!-- [innervoiceover]:/pages/ivo -->
<!-- [read]:/pages/ivo -->
<!-- [modifytheloss]:/pages/mtl -->
<!-- https://sarahciston.com/MtL.html{:target="_blank"}  -->
