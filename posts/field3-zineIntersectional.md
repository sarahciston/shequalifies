---
title: zine 1, why IAI
parent: intersectional AI
last_modified_date: 2020-08-23 05:00
---

<main class="zine" markdown="1">
<section class="zine-page page-1" markdown="1">
## why intersectional AI?

This mini-field-guide is part of a series looking at ideas, approaches, and examples bringing Intersectionality to AI. 

#### ["How is AI shifting power?"](nature.com/articles/d41586-020-02003-2){:target="_blank"} 

This is the most important question to ask, rather than is this technology biased, fair, or good, says [Pratyusha Ria Kalluri](http://riakalluri.com/){:target="_blank"}. They are a founder of the Radical AI Network and an AI researcher working on "ai and art that antioppressive and queerly beautiful." 

#### what intersectionality isn't 

Intersectionality is often misunderstood: In its original formulation by Kimberlé Crenshaw in 1989, says Brittney Cooper (2016), it was not merely shorthand for discussing individual identity representation. Critics point out how this has allowed for even more granular marketing to these categories as they become visible to and targeted by capitalism (Chun 2018, 85). Rather, intersectionality is about power. It examines and critiques systems of power and how those systems structure themselves to impact groups and individuals unequally. 

</section>

<section class="zine-page page-2" markdown="1">
#### what intersectionality is, what it can offer tech
Catherine D'Ignazio and Lauren Klein (2019) agree that intersectionality not only describes different aspects of an individual's position, but also "intersecting forces of privilege and oppression at work in a given society. Oppression involves the systematic mistreatment of certain groups of people by other groups. It happens when power is not distributed equally” (7–-8). Intersectional feminism insists on not just meeting the needs of the most priviledged (white) women when arguing for feminism, or the needs of only Black men when combating anti-Blackness, but instead suggests that those with overlapping oppressions such as Black women face unique additional oppression; by addressing their circumstances, for example, life improves for everyone. 

Jacqueline Wernimont (2018) uses the metaphor of a matrix, as in, "the media in which something is generated or developed. As a generative form, the matrix is a powerful way of understanding and critiquing binary logics and simple, progressive narratives" (11). Citing Vivian M. May, she says it also grounds intersectional practice and thought, "intersectional work focuses on 'enmeshed multiplicities,' including but not limited to those of race and gender. It also entails a commitment to 'resistant forms of knowing' [...]. The matrix logic of intersectional feminism 'considers how inequalities intermingle,' and stresses linkages between 'the structural and experiential, and the material and the discursive'" (11). This suggests how intersectionality could offer a different lens through which to approach AI and technology in general. Intersectional AI as sketched out here is indebted to Crenshaw's original definition, as well as the concept's long lineages within Black and indigenous thought, for its critical lens to analyze technology and for its creative approach to redesigning it.[^more]

<!-- [A matrix material can be the support for intersecting fibers...] moire, mesh net sifts sorts what stays and goes, could be the matrix what supports the new thing that emerges out of it-->

[^more]: Amelia Jones (2013) suggests a switch from thinking of fixed "identity" to instead "identification" that allows for the slippery, time-based, contingent nature of these concepts: "we must continue to acknowledge the ways in which bodies are identified and positioned in the world (including our own), while refusing to allow our assumptions about identity to congeal into fixed binaries" (6). This also resonates with Tara McPherson's (2018) idea of the "intersectional cut," which reclaims intersectionality as "a fuzzy edge and a point" (98), that is, acknowledging after Karen Barad the role of the lens in looking (and the ability to shift that lens to shift the view).  

</section>

<section class="zine-page page-3" markdown="1">
#### against inclusion, decentering instead
Guillermo Gómez-Peña says the high-tech world does not question itself as central, nor where it draws its borders: "We are no longer trying to persuade anyone that we are worthy of inclusion (we are de facto insiders/outsiders at the same time, or temporary insiders perhaps, and we know it). [...] What we wish is to remap the hegemonic cartography of cyberspace; to "politicize" the debate; to develop a multi centric theoretical understanding of the cultural, political and aesthetic possibilities of new technologies; to exchange a different sort of information (mytho poetical, activist, per formative, imagistic) [...]."[^continues]

Importantly, Christina Dunbar-Hester (2020) argues that "diversity and inclusion" fixes completely miss the problem---not only because it ignores the workers of the Global South[^workers] but also because it reverses the problem's cause and effect: "to frame social inequality as a question of diversity in technological production, and to expect to change wider inequities by adding 'diverse' individuals to technical cultures, is to misunderstand how the distribution of various social identities in a given sector are _outgrowths of differential social power_, not the other way around" (16).
 
By a similar logic, removing bias from algorithmic systems---even if that were possible (which, no.)---does not remove bias from culture, nor does it replace it with anything. Often, even well-meaning efforts to "remove" bias from systems fall back on quantitative/computational methods or resort to representation, which mirror the problems they claim to address, potentially even making tools to be misused in the future: "Representation as a goal may also result in accepting (and reproducing) notions of fixity in terms of social identity. This should raise skepticism" (236). These approaches do not examine the structure of the system itself, the logic upon which it is founded, both materially and intellectually. They do not ask who is creating, contributing, or benefitting from its operation. "Diversity [and, I argue, bias examination] is necessary, but not sufficient; it represents a shortcut in what should be a deeper conversation about values and justice" (Dunbar-Hester 2020, 241).
</section>

[^continues]: He continues: "and to hopefully do all this with humor and intelligence. Chicano artists in particular wish to "brownify" virtual space; to "spanglishize the net", and "infect" the lingua franca; [...] to find innovative grassroots applications to new technologies; to help the Latino youth literally exchange their guns for computers and video cameras, and to link all community centers through the net."

[^workers]: Lisa Nakamura, Sarah T. Roberts, and others have pointed to the many female and BIPOC tech workers who go unrecognized because their work is not the glamor work of tech, from the physically-taxing work of chip manufacturing on New Mexico reservations to the emotionally-taxing work of content moderation at sites just-off big tech campuses. Christina Dunbar-Hester (2020) argues that even "hacking has never been centered exclusively around white men in the Global North. Furthermore, some of what is required here is to simply shift the frame of what counts as hacking: to redraw boundaries to _place social and historical analysis and infrastructural care work within the purview of hacking._ In combination, these analytical adjustments can illuminate the 'others' of hacking---who are already here" (242). 


<section class="zine-page page-4" markdown="1">
#### algorithmic histories predict our futures

"Codes are both reflective and predictive. They have a past and a future," (3) says Ruja Benjamin (2019), author of _Race After Technology_. Benjamin uses <span class="purple-inline">**race critical code studies** (see p7)</span> to show how race itself is a technology that has been used to discriminate, even in decision-making processes that appear "neutral" or outside the scope of algorithms: "even just deciding what problem needs solving requires a host of judgments" (5).

"Data for Black Lives co-founder Yeshimabeit Milner reminds us that “[t]he decision to make every Black life count as three-fifths of a person was embedded in the electoral college, an algorithm that continues to be the basis of our current democracy." (5) 
{: .purple-inline}

#### What does it mean to say "race is a technology"?
Benjamin says, "this is an invitation to consider racism in relation to other forms of domination as not just an ideology or history, but as a set of technologies that generate patterns of social relations, and these become Black-boxed as natural, inevitable, automatic. As such, this is also an invitation to refuse the illusion of inevitability in which technologies of race come wrapped" (23).
</section>

<section class="zine-page page-5" markdown="1">
#### alternate histories, alternative approaches? 

The algorithm itself is an ancient, not exclusive to high-tech startups. "[C]laiming that abstract techniques of knowledge and artificial metalanguages belong uniquely to the modern industrial West is not only historically inaccurate but also an act and one of implicit _epistemic colonialism_ towards cultures of other places and other times. [...A]lgorithms are among the most ancient and material practices, predating many human tools and all modern machines" (Pasquinelli 2019). Instead of assuming AI must be how it is, it's worth asking what other cultural values might come with algorithms _from_ other cultures (not to appropriate those, but rather to decenter the supremacy of white neoliberal ways of knowing).

#### whiteness and AI
Benjamin argues that, "what appears to be an absence in terms of being 'cultureless' works more like a superpower. Invisibility, with regard to Whiteness, offers immunity. To be unmarked by race allows you to reap the benefits but escape responsibility for your role in an unjust system" (2). Although invisible, whiteness is a determining factor shaping AI, "structuring whose literal voice gets embodied in AI. In celebrating diversity, tokenistic approaches to tech development fail to acknowledge how the White aesthetic colors AI. The 'blandness' of Whiteness [...] is treated by programmers as normal, universal, and appealing" (15).
</section>

<section class="zine-page page-6" markdown="1">
#### the reach of AI requires intersectionality at every level

In "Anatomy of an AI System," Kate Crawford and Vladan Joler (2018) map out the vast tangible effects of convenient, immaterial-seeming AI that require: "a vast planetary network, fueled by the extraction of non-renewable materials, labor, and data. [...] it is hard to ‘see’ any of these processes individually, let alone collectively." And understanding isn't enough, they argue, "without forms of real choice, and corporate accountability, mere transparency won’t shift the weight of the current power asymmetries."

"To the casual observer, it looks like it has never been easier to build AI [creating] a false idea of the ‘democratization’ of AI. While ‘off the shelf’ machine learning tools, like TensorFlow, are becoming more accessible from the point of view of setting up your own system, the underlying logics of those systems, and the datasets for training them are accessible to and controlled by very few entities. In the dynamic of dataset collection through platforms like Facebook, users are feeding and training the neural networks with behavioral data, voice, tagged pictures and videos or medical data. In an era of extractivism, the real value of that data is controlled and exploited by the very few at the top of the pyramid." (Crawford/Joler 2018)[^crawford]
{: .purple-inline }

[^crawford]: Without an intersectional approach, including but not limited to more diverse participation in the design of, implementation of, and audience for AI systems, technological power and tangible resources will continue to be consolidated to benefit very few. The stakes are high and wide: "At every level contemporary technology is deeply rooted in and running on the exploitation of human bodies" (Crawford/Joler 2018). 

</section>

<section class="zine-page page-7" markdown="1">
#### race critical code studies
Critical code studies is an approach that suggests reading the code itself for its style, the influences of its authors and the choices they make, just like any other kind of writing: "lines of code are not value-neutral and can be analyzed using the theoretical approaches applied to other [texts] in addition to particular interpretive methods developed particularly for the discussions of programs" (Marino 2006). Because so much of coding originates not from a blank screen but adapts existing scripts and examples, being able to parse code both technically and critically is essential. Ruja Benjamin (2019) combines this approach with critical race theory for her "race critical code studies" methodology, which looks "at how race and racism impact who has access to new devices, as well as how technologies are produced in the first place" (22). 

#### restorative processing, infrastructures of care
Intersectional AI must be not just about remedying bias but more broadly about instituting infrastructures of care. For what and for whom do we truly care? And how do we demonstrate those values by reorienting (after Sara Ahmed) ourselves, our attention, our resources? Along with all of the harm caused by technological and cultural bias, framing these issues in the positive rather than the negative makes this a question, not just of what to remove, but of what to build in its place. 
</section>

<section class="zine-page page-8" markdown="1">
#### a better AI is possible: love notes to intersectional innovators

Besides activism like protest or critical writing, another way to make change is "argument by technology"---aka making stuff---or even "hacks of open-technology communities themselves, which directly flow from practitioners' habit of reflective technical engagement" (Dunbar-Hester 2020, 50).

_So how do I make intersectional AI?_ For more info, see the other zines in this library, and for inspiration check out these makers and organizations helping envision different computational futures (an utterly non-exhaustive list):

- [Afrotechtopia](https://www.afrotectopia.org/){:target="_blank"}
- [<CTRL + SHIFT>](https://www.ctrlshift.club/)
- [Data for Black Lives](https://d4bl.org/){:target="_blank"}
- [@datahealing](https://www.are.na/neema-xx/data-healing){:target="_blank"} & [@cyberdoula](https://www.instagram.com/cyberdoula/){:target="_blank"} 
- [Deep Lab](http://www.deeplab.net){:target="_blank"}
- [Queer.AI](https://queer.ai/){:target="_blank"}
- [Tiny Tech Zines](https://www.instagram.com/tinytechzines/){:target="_blank"}
- [Virtual Care Lab](https://www.instagram.com/virtualcarelab/){:target="_blank"}

</section>
</main>




<style>
  
/* Any styles that you want to apply **just** when the zine is printed go in here! */

@media print {

  .main-header, 
  .breadcrumb-nav, 
  .site-title, 
  .page-header, 
  .menu, 
  .footnotes,
  .comments,
  .newComment,
  .post ,
  .site-footer { 
    display: none;
  }
  
  body {
    font-size: 58%; /* 69%, 33% */
  }
  
  a {
    color: inherit;
    text-decoration: none;
  }
  
  /*
   a:after {
        content:" (" attr(href) ") ";
        color: $primary;
  }
  */
 
  .mini-img {
    max-width: 4.4rem;
  }
  
  /* The styles below here are specifically for creating the page layout.-> DON'T CHANGE THESE <- unless you know what youre doing!
  */
  
  @page {
    size: landscape;
    margin: 1cm; /*0;*/
    bleed: 0;
  }
                                                                                                  
  @page :last {
    display: none;
  }
                                                                                                  
                                                                                                                            
  .zine {
    width: 100vw;
    height: 100vh;
    display: grid;
    gap: 1.5px;
    background: lightgrey;
    grid-template-areas:
      "page-5 page-4 page-3 page-2"
      "page-6 page-7 page-8 page-1";
  }

  .zine-page {
    background: white;
    padding: .2rem;
    overflow: hidden;
  }

  .page-5, .page-4, .page-3, .page-2 {
    transform: rotate(180deg) translateX(-0.1px);
  }

  .page-1 {
    grid-area: page-1;

  }

  .page-2 {
    grid-area: page-2;

  }

  .page-3 {
    grid-area: page-3;
  }

  .page-4 {
    grid-area: page-4;
  }

  .page-5 {
    grid-area: page-5;
  }

  .page-6 {
    grid-area: page-6;
  }

  .page-7 {
    grid-area: page-7;
  }

  .page-8 {
    grid-area: page-8;
  }
  
}
</style>
